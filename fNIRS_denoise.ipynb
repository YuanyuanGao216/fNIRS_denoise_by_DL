{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as tordata\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(tordata.Dataset):\n",
    "    def __init__(self, noisy_data, clean_data=None):\n",
    "        self.noisy_data = noisy_data\n",
    "        self.clean_data = clean_data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        noisy_data = self.noisy_data[index]\n",
    "        clean_data = -1\n",
    "        if self.clean_data is not None:\n",
    "            clean_data = self.clean_data[index]\n",
    "        return noisy_data, clean_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.noisy_data.shape[0]\n",
    "\n",
    "# %% define nn models\n",
    "\n",
    "class Net_4layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_4layers, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, 11,padding = 5)\n",
    "        self.conv2 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv3 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv4 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv5 = nn.Conv1d(32,1,3,padding = 1)\n",
    "        self.pool = nn.MaxPool1d(2,padding = 0)\n",
    "        self.up = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b_s, f_n = x.size()\n",
    "        x = x.view(b_s, 1, f_n)\n",
    "        x1 = x[:, :, :512]\n",
    "        x2 = x[:, :, 512:]\n",
    "#         print('input layer:')\n",
    "#         print(x1.size())\n",
    "#         print(x2.size())\n",
    "\n",
    "        x1 = self.pool(F.relu(self.conv1(x1)))\n",
    "        x2 = self.pool(F.relu(self.conv1(x2)))\n",
    "#         print('1st layer:')\n",
    "#         print(x1.size())\n",
    "#         print(x2.size())\n",
    "        \n",
    "        x1 = self.pool(F.relu(self.conv2(x1)))\n",
    "#        print('2nd layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.pool(F.relu(self.conv2(x2)))\n",
    "        x1 = self.up(F.relu(self.conv3(x1)))\n",
    "#        print('3rd layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.up(F.relu(self.conv3(x2)))\n",
    "        x1 = self.up(F.relu(self.conv4(x1)))\n",
    "#        print('4th layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.up(F.relu(self.conv4(x2)))\n",
    "        x1 = self.conv5(x1)\n",
    "#        print('5th layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.conv5(x2)\n",
    "        x = torch.cat((x1, x2), dim=2)\n",
    "        b_s, _, f_n = x.size()\n",
    "        x = x.view(b_s, -1)\n",
    "        return x\n",
    "class Net_8layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_8layers, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, 11,padding = 5)\n",
    "        self.conv2 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv3 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv4 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv5 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv6 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv7 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv8 = nn.Conv1d(32,32,3,padding = 1)\n",
    "        self.conv9 = nn.Conv1d(32,1,3,padding = 1)\n",
    "        self.pool = nn.MaxPool1d(2,padding = 0)\n",
    "        self.up = nn.Upsample(scale_factor=2)\n",
    "        self\n",
    "\n",
    "    def forward(self, x):\n",
    "        b_s, f_n = x.size()\n",
    "        x = x.view(b_s, 1, f_n)\n",
    "        x1 = x[:, :, :512]\n",
    "        x2 = x[:, :, 512:]\n",
    "        \n",
    "        x1 = self.pool(F.relu(self.conv1(x1)))\n",
    "#         print('1st layer:')\n",
    "#         print(x1.size())\n",
    "        x2 = self.pool(F.relu(self.conv1(x2)))\n",
    "        \n",
    "        x1 = self.pool(F.relu(self.conv2(x1)))\n",
    "#        print('2nd layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.pool(F.relu(self.conv2(x2)))\n",
    "        \n",
    "        x1 = self.pool(F.relu(self.conv3(x1)))\n",
    "#        print('3rd layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.pool(F.relu(self.conv3(x2)))\n",
    "        \n",
    "        x1 = self.pool(F.relu(self.conv4(x1)))\n",
    "#        print('4th layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.pool(F.relu(self.conv4(x2)))\n",
    "        \n",
    "        x1 = self.up(F.relu(self.conv5(x1)))\n",
    "#        print('5th layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.up(F.relu(self.conv5(x2)))\n",
    "        \n",
    "        x1 = self.up(F.relu(self.conv6(x1)))\n",
    "#        print('6th layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.up(F.relu(self.conv6(x2)))\n",
    "        \n",
    "        x1 = self.up(F.relu(self.conv7(x1)))\n",
    "#        print('7th layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.up(F.relu(self.conv7(x2)))\n",
    "        \n",
    "        x1 = self.up(F.relu(self.conv8(x1)))\n",
    "#        print('8th layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.up(F.relu(self.conv8(x2)))\n",
    "        \n",
    "        x1 = self.conv9(x1)\n",
    "#        print('9th layer:')\n",
    "#        print(x1.size())\n",
    "        x2 = self.conv9(x2)\n",
    "        \n",
    "        x = torch.cat((x1, x2), dim=2)\n",
    "        b_s, _, f_n = x.size()\n",
    "        x = x.view(b_s, -1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNR(y_pred):\n",
    "    batch_size, f_n = y_pred.size()\n",
    "    y_pred = y_pred.view(batch_size, 2, -1)\n",
    "    SNR = torch.std(y_pred, axis=2).mean()\n",
    "    return SNR\n",
    "\n",
    "def std_loss(y_pred):\n",
    "    batch_size, f_n = y_pred.size()\n",
    "    y_pred = y_pred/1000000\n",
    "    y_pred = y_pred.view(batch_size, 1, f_n)\n",
    "    HbO = y_pred[:, :, :512]\n",
    "    HbR = y_pred[:, :, 512:]\n",
    "    d1 = 148*HbO+384*HbR\n",
    "    d2 = 252*HbO+179*HbR\n",
    "    d = torch.cat((d1,d2),axis = 1)\n",
    "    d = d*2.376*6\n",
    "    # batch_size * 2\n",
    "    std_diff = torch.std(d[:,:,1:]-d[:,:,:-1],axis = 2)\n",
    "#    max_diff = torch.zeros((batch_size,2,512-1),dtype=torch.double).cuda()\n",
    "    \n",
    "    diff = []\n",
    "    for ii in range(4):\n",
    "        lag = torch.abs(d[:,:,ii+1:]-d[:,:,:-(ii+1)])\n",
    "        zero_pad = torch.zeros((batch_size,2,ii)).cuda().double()\n",
    "        lag_zeros = torch.cat((lag,zero_pad),axis = 2)\n",
    "        diff.append(lag_zeros.unsqueeze(0))\n",
    "#        max_diff = torch.max(lag_zeros, max_diff,out=None)\n",
    "    # 4 * batch_size * 2 *511\n",
    "    diff = torch.cat(diff, axis=0)    \n",
    "    \n",
    "    # 1 * batch * 2 * 1\n",
    "    mc_thresh = (std_diff*10).unsqueeze(-1).unsqueeze(0)\n",
    "    # 4 * batch_size * 2 *511\n",
    "    mask_mc = (diff > mc_thresh).double()\n",
    "    amp_thresh = (torch.ones(diff.size(),dtype=torch.double)*200).cuda()\n",
    "    mask_amp = (diff > amp_thresh).double()\n",
    "    mc_loss = (diff * mask_mc).sum() / (mask_mc.sum()+1e-7)\n",
    "    amp_loss = (diff * mask_amp).sum() / (mask_amp.sum()+1e-7)\n",
    "#    max_mc = torch.max(max_diff,mc_thresh,out=None)\n",
    "#    amp_mc = torch.max(max_diff,amp_thresh,out=None)\n",
    "#    std_loss_value = torch.max(max_mc+amp_mc)\n",
    "    return mc_loss + amp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32690, 1024)\n",
      "(4086, 1024)\n",
      "(4086, 1024)\n",
      "(179, 1024)\n"
     ]
    }
   ],
   "source": [
    "## load data\n",
    "np.random.seed(50)\n",
    "X_train = scipy.io.loadmat('Processed_data/HRF_train_noised.mat')\n",
    "X_train = X_train['HRF_train_noised'];\n",
    "n = X_train.shape[0];\n",
    "X_train = np.concatenate((X_train[0:int(n/2),:],X_train[int(n/2):,:]),axis = 1)\n",
    "X_val = scipy.io.loadmat('Processed_data/HRF_val_noised.mat')\n",
    "X_val = X_val['HRF_val_noised'];\n",
    "n = X_val.shape[0];\n",
    "X_val = np.concatenate((X_val[0:int(n/2),:],X_val[int(n/2):,:]),axis = 1)\n",
    "X_test = scipy.io.loadmat('Processed_data/HRF_test_noised.mat')\n",
    "X_test = X_test['HRF_test_noised'];\n",
    "n = X_test.shape[0];\n",
    "X_test = np.concatenate((X_test[0:int(n/2),:],X_test[int(n/2):,:]),axis = 1)\n",
    "\n",
    "Y_train = scipy.io.loadmat('Processed_data/HRF_train.mat')\n",
    "Y_train = Y_train['HRF_train'];\n",
    "n = Y_train.shape[0];\n",
    "Y_train = np.concatenate((Y_train[0:int(n/2),:],Y_train[int(n/2):,:]),axis = 1)\n",
    "Y_val = scipy.io.loadmat('Processed_data/HRF_val.mat')\n",
    "Y_val = Y_val['HRF_val'];\n",
    "n = Y_val.shape[0];\n",
    "Y_val = np.concatenate((Y_val[0:int(n/2),:],Y_val[int(n/2):,:]),axis = 1)\n",
    "Y_test = scipy.io.loadmat('Processed_data/HRF_test.mat')\n",
    "Y_test = Y_test['HRF_test'];\n",
    "n = Y_test.shape[0];\n",
    "Y_test = np.concatenate((Y_test[0:int(n/2),:],Y_test[int(n/2):,:]),axis = 1)\n",
    "\n",
    "X_real_HbO = scipy.io.loadmat('Processed_data/Real_HbO.mat')\n",
    "X_real_HbO = X_real_HbO['Real_HbO'];\n",
    "X_real_HbR = scipy.io.loadmat('Processed_data/Real_HbR.mat')\n",
    "X_real_HbR = X_real_HbR['Real_HbR'];\n",
    "X_real = np.concatenate((X_real_HbO,X_real_HbR),axis = 1)\n",
    "\n",
    "X_train = X_train*1000000\n",
    "X_val = X_val*1000000\n",
    "X_test = X_test*1000000\n",
    "\n",
    "Y_train = Y_train*1000000\n",
    "Y_val = Y_val*1000000\n",
    "Y_test = Y_test*1000000\n",
    "\n",
    "X_real = X_real*1000000\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(X_real.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.where(np.isnan(X_train)))\n",
    "print(np.where(np.isnan(X_val)))\n",
    "print(np.where(np.isnan(Y_train)))\n",
    "print(np.where(np.isnan(Y_val)))\n",
    "\n",
    "print(np.where(np.isinf(X_train)))\n",
    "print(np.where(np.isinf(X_val)))\n",
    "print(np.where(np.isinf(Y_train)))\n",
    "print(np.where(np.isinf(Y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:,:]\n",
    "Y_train = Y_train[:,:]\n",
    "X_val = X_val[:,:]\n",
    "Y_val = Y_val[:,:]\n",
    "X_test = X_test[:,:]\n",
    "Y_test = Y_test[:,:]\n",
    "X_real = X_real[:,:]\n",
    "\n",
    "train_set = Dataset(X_train, Y_train)\n",
    "val_set = Dataset(X_val, Y_val)\n",
    "test_set = Dataset(X_test, Y_test)  \n",
    "real_set = Dataset(X_real)  \n",
    "# %% define data loaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "        dataset = train_set,\n",
    "        batch_size=512,\n",
    "        sampler = tordata.RandomSampler(train_set),\n",
    "        num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "        dataset = val_set, \n",
    "        batch_size=512,\n",
    "        sampler = tordata.SequentialSampler(val_set),\n",
    "        num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "        dataset = test_set, \n",
    "        batch_size=512,\n",
    "        sampler = tordata.SequentialSampler(test_set),\n",
    "        num_workers=2)\n",
    "\n",
    "realloader = torch.utils.data.DataLoader(\n",
    "        dataset = real_set, \n",
    "        batch_size=32,\n",
    "        sampler = tordata.SequentialSampler(real_set),\n",
    "        num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% trian and validate\n",
    "data_loaders = {\"train\": trainloader, \"val\": valloader}\n",
    "model = ['4layers','8layers']\n",
    "\n",
    "n_epochs = 100\n",
    "print('start')\n",
    "for model_name in model:\n",
    "    print('Model:', model_name)\n",
    "    if model_name == '4layers':\n",
    "        net = Net_4layers().cuda()\n",
    "    elif model_name == '8layers':\n",
    "        net = Net_8layers().cuda()\n",
    "    train_loss1 = []\n",
    "    val_loss1 = []\n",
    "    train_loss2 = []\n",
    "    val_loss2 = []\n",
    "    train_loss3 = []\n",
    "    val_loss3 = []\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    scheduler = StepLR(optimizer, step_size = 100, gamma=0.1)\n",
    "    lowest_val_loss = 1e6;\n",
    "    hdf5_filepath = \"networks\\\\\" + model_name\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        print('Epoch {}/{}'.format(epoch, n_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                net.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                net.train(False)\n",
    "            running_loss1 = 0.0\n",
    "            running_loss2 = 0.0\n",
    "            running_loss3 = 0.0\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(data_loaders[phase], 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, y_true = data\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs.cuda().float())\n",
    "                outputs = outputs.double()\n",
    "                mse_loss = nn.MSELoss()\n",
    "                loss1 = mse_loss(outputs, y_true.cuda())\n",
    "                loss2 = SNR(outputs)\n",
    "                loss3 = std_loss(outputs)\n",
    "                print('-'*10)\n",
    "                print(loss1)\n",
    "                print(loss2)\n",
    "                print(loss3)\n",
    "                loss = loss1 + 1e3 * loss2 + 1e4*loss3\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                running_loss1 += loss1.item()\n",
    "                running_loss2 += loss2.item()\n",
    "                running_loss3 += loss3.item()\n",
    "                running_loss += loss.item()\n",
    "            epoch_loss1 = running_loss1 / len(data_loaders[phase])\n",
    "            epoch_loss2 = running_loss2 / len(data_loaders[phase])\n",
    "            epoch_loss3 = running_loss3 / len(data_loaders[phase])\n",
    "            epoch_loss = running_loss / len(data_loaders[phase])\n",
    "            if phase == 'train':\n",
    "                train_loss1.append(epoch_loss1)\n",
    "                train_loss2.append(epoch_loss2)\n",
    "                train_loss3.append(epoch_loss3)\n",
    "                train_loss.append(epoch_loss)  # Set model to training mode\n",
    "            else:\n",
    "                val_loss1.append(epoch_loss1)\n",
    "                val_loss2.append(epoch_loss2)\n",
    "                val_loss3.append(epoch_loss3)\n",
    "                val_loss.append(epoch_loss)\n",
    "                if epoch_loss < lowest_val_loss:\n",
    "                    lowest_val_loss = epoch_loss\n",
    "                    torch.save(net.state_dict(), hdf5_filepath)\n",
    "            print('{} Loss: {:.10f};  Loss1: {:.10f};  Loss2: {:.10f}; Loss3: {:.10f}'.format(\n",
    "                    phase, epoch_loss, epoch_loss1, epoch_loss2, epoch_loss3))\n",
    "            scheduler.step()\n",
    "\n",
    "    print('Finished Training')\n",
    "    plt.figure()\n",
    "    vl, = plt.plot(val_loss1,'r')\n",
    "    tl, = plt.plot(train_loss1,'b')\n",
    "    plt.legend([tl,vl],['training loss', 'validation loss'],)\n",
    "    figurepath = \"figures\\\\\" + model_name+\"_1\"+\".png\"\n",
    "    plt.savefig(figurepath, transparent=True)\n",
    "    plt.figure()\n",
    "    vl, = plt.plot(val_loss2,'r')\n",
    "    tl, = plt.plot(train_loss2,'b')\n",
    "    plt.legend([tl,vl],['training loss', 'validation loss'],)\n",
    "    figurepath = \"figures\\\\\" + model_name+\"_2\"+\".png\"\n",
    "    plt.savefig(figurepath, transparent=True)\n",
    "    plt.figure()\n",
    "    vl, = plt.plot(val_loss3,'r')\n",
    "    tl, = plt.plot(train_loss3,'b')\n",
    "    plt.legend([tl,vl],['training loss', 'validation loss'],)\n",
    "    figurepath = \"figures\\\\\" + model_name+\"_3\"+\".png\"\n",
    "    plt.savefig(figurepath, transparent=True)\n",
    "    plt.figure()\n",
    "    vl, = plt.plot(val_loss,'r')\n",
    "    tl, = plt.plot(train_loss,'b')\n",
    "    plt.legend([tl,vl],['training loss', 'validation loss'],)\n",
    "    figurepath = \"figures\\\\\" + model_name+\"_all\"+\".png\"\n",
    "    plt.savefig(figurepath, transparent=True)\n",
    "    print('Finished Fig saving')\n",
    "\n",
    "    trainlosspath = \"Processed_data\\\\train_loss_\" + model_name+\".txt\"\n",
    "    np.savetxt(trainlosspath, np.array(train_loss), fmt=\"%s\")\n",
    "    vallosspath = \"Processed_data\\\\val_loss_\" + model_name+\".txt\"\n",
    "    np.savetxt(vallosspath, np.array(val_loss), fmt=\"%s\")\n",
    "    print('Finished writing loss files')\n",
    "\n",
    "    net.load_state_dict(torch.load(hdf5_filepath))\n",
    "    print('loaded nn file')\n",
    "\n",
    "    Y_test = []\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs = data[0]\n",
    "        outputs = net(inputs.cuda().float())\n",
    "        Y_test.append(outputs.cpu().data.numpy())\n",
    "    Y_test = np.concatenate(Y_test, axis=0)\n",
    "    Y_test = Y_test/1000000\n",
    "    savefilepath = \"Processed_data\\\\Test_NN_\" + model_name+\".mat\"\n",
    "    scipy.io.savemat(savefilepath,{'Y_test': Y_test})\n",
    "    \n",
    "    Y_real = []\n",
    "    for i, data in enumerate(realloader, 0):\n",
    "        inputs = data[0]\n",
    "        outputs = net(inputs.cuda().float())\n",
    "        Y_real.append(outputs.cpu().data.numpy())\n",
    "    Y_real = np.concatenate(Y_test, axis=0)\n",
    "    Y_real = Y_real/1000000\n",
    "    savefilepath = \"Processed_data\\\\Real_NN_\" + model_name+\".mat\"\n",
    "    scipy.io.savemat(savefilepath,{'Y_real': Y_real})\n",
    "    \n",
    "    print('Saved predited data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "X, = plt.plot(X_test[0,:],'r')\n",
    "Y, = plt.plot(Y_test[0,:],'b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
